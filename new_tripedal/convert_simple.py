#!/usr/bin/env python3
"""
ç®€å•çš„.ptåˆ°ONNXè½¬æ¢è„šæœ¬
é€‚ç”¨äºå¤§å¤šæ•°Isaac Labè®­ç»ƒçš„æ¨¡å‹

ä½¿ç”¨æ–¹æ³•:
python convert_simple.py model.pt

è¿™ä¸ªè„šæœ¬ä¼š:
1. åŠ è½½.ptæ–‡ä»¶
2. åˆ†ææ¨¡å‹ç»“æ„
3. è½¬æ¢ä¸ºONNXæ ¼å¼
"""

import os
import sys
import torch
import torch.onnx

def inspect_checkpoint(pt_file):
    """æ£€æŸ¥checkpointæ–‡ä»¶çš„ç»“æ„"""
    print(f"ğŸ” æ£€æŸ¥æ–‡ä»¶: {pt_file}")
    
    try:
        checkpoint = torch.load(pt_file, map_location='cpu', weights_only=False)
        print("âœ… æ–‡ä»¶åŠ è½½æˆåŠŸ")
        
        print(f"\nğŸ“‹ Checkpointç»“æ„:")
        for key in checkpoint.keys():
            if isinstance(checkpoint[key], dict):
                print(f"  {key}: dict (åŒ…å« {len(checkpoint[key])} ä¸ªé”®)")
                # æ˜¾ç¤ºå‰å‡ ä¸ªå­é”®
                sub_keys = list(checkpoint[key].keys())[:5]
                for sub_key in sub_keys:
                    print(f"    - {sub_key}")
                if len(checkpoint[key]) > 5:
                    print(f"    ... è¿˜æœ‰ {len(checkpoint[key])-5} ä¸ªé”®")
            elif isinstance(checkpoint[key], torch.Tensor):
                print(f"  {key}: Tensor {checkpoint[key].shape}")
            else:
                print(f"  {key}: {type(checkpoint[key])}")
        
        return checkpoint
        
    except Exception as e:
        print(f"âŒ æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
        return None

def extract_model_info(checkpoint):
    """æå–æ¨¡å‹ä¿¡æ¯"""
    
    # æŸ¥æ‰¾actorç½‘ç»œæƒé‡
    actor_weights = {}
    
    # å°è¯•ä¸åŒçš„å¯èƒ½è·¯å¾„
    possible_paths = [
        checkpoint,  # ç›´æ¥åœ¨æ ¹ç›®å½•
        checkpoint.get('model', {}),  # åœ¨modelé”®ä¸‹
        checkpoint.get('model_state_dict', {}),  # åœ¨model_state_dicté”®ä¸‹ - æ–°å¢
        checkpoint.get('actor_critic', {}),  # åœ¨actor_criticé”®ä¸‹
        checkpoint.get('policy', {}),  # åœ¨policyé”®ä¸‹
        checkpoint.get('state_dict', {}),  # åœ¨state_dicté”®ä¸‹
    ]
    
    for state_dict in possible_paths:
        if not isinstance(state_dict, dict):
            continue
            
        # æŸ¥æ‰¾actorç›¸å…³çš„æƒé‡
        for key, value in state_dict.items():
            if isinstance(value, torch.Tensor) and 'actor' in key.lower() and ('weight' in key or 'bias' in key):
                actor_weights[key] = value
                print(f"ğŸ” æ‰¾åˆ°æƒé‡: {key} {value.shape}")
    
    if not actor_weights:
        print("âŒ æœªæ‰¾åˆ°actoræƒé‡")
        print("ğŸ“‹ å°è¯•æ˜¾ç¤ºæ‰€æœ‰åŒ…å«'actor'çš„é”®:")
        for state_dict in possible_paths:
            if not isinstance(state_dict, dict):
                continue
            for key in state_dict.keys():
                if 'actor' in key.lower():
                    print(f"  å‘ç°: {key}")
        return None
    
    print(f"âœ… æ‰¾åˆ° {len([k for k in actor_weights.keys() if 'weight' in k])} ä¸ªactorå±‚")
    
    # åˆ†æç½‘ç»œç»“æ„
    layer_sizes = []
    weight_keys = sorted([k for k in actor_weights.keys() if 'weight' in k])
    
    for key in weight_keys:
        weight = actor_weights[key]
        if len(weight.shape) == 2:
            in_size, out_size = weight.shape[1], weight.shape[0]
            layer_sizes.append((in_size, out_size))
            print(f"  å±‚ {key}: {in_size} -> {out_size}")
    
    if not layer_sizes:
        print("âŒ æ— æ³•ç¡®å®šç½‘ç»œç»“æ„")
        return None
    
    return {
        'layer_sizes': layer_sizes,
        'weights': actor_weights,
        'input_size': layer_sizes[0][0],
        'output_size': layer_sizes[-1][1]
    }

def create_simple_model(model_info):
    """åˆ›å»ºç®€å•çš„PyTorchæ¨¡å‹"""
    
    layers = []
    layer_sizes = model_info['layer_sizes']
    
    for i, (in_size, out_size) in enumerate(layer_sizes):
        # åˆ›å»ºçº¿æ€§å±‚
        layer = torch.nn.Linear(in_size, out_size)
        layers.append(layer)
        
        # æ·»åŠ æ¿€æ´»å‡½æ•°ï¼ˆæœ€åä¸€å±‚é™¤å¤–ï¼‰
        if i < len(layer_sizes) - 1:
            layers.append(torch.nn.ReLU())
    
    model = torch.nn.Sequential(*layers)
    
    # åŠ è½½æƒé‡ - æ”¹è¿›çš„åŒ¹é…é€»è¾‘
    weights = model_info['weights']
    weight_keys = sorted([k for k in weights.keys() if 'weight' in k])
    
    print(f"ğŸ”§ å¼€å§‹åŠ è½½æƒé‡ï¼Œæ‰¾åˆ°çš„æƒé‡å±‚: {weight_keys}")
    
    with torch.no_grad():
        linear_layer_idx = 0
        for i, (layer_name, layer) in enumerate(model.named_children()):
            if isinstance(layer, torch.nn.Linear):
                if linear_layer_idx < len(weight_keys):
                    # ç›´æ¥æŒ‰é¡ºåºåŒ¹é…æƒé‡
                    weight_key = weight_keys[linear_layer_idx]
                    bias_key = weight_key.replace('weight', 'bias')
                    
                    if weight_key in weights:
                        layer.weight.data = weights[weight_key]
                        print(f"âœ… åŠ è½½æƒé‡: {weight_key} -> å±‚{linear_layer_idx}")
                    
                    if bias_key in weights:
                        layer.bias.data = weights[bias_key]
                        print(f"âœ… åŠ è½½åç½®: {bias_key} -> å±‚{linear_layer_idx}")
                    else:
                        print(f"âš ï¸ æœªæ‰¾åˆ°åç½®: {bias_key}")
                
                linear_layer_idx += 1
    
    return model

def convert_to_onnx(model, input_size, output_file):
    """è½¬æ¢æ¨¡å‹ä¸ºONNXæ ¼å¼"""
    
    try:
        model.eval()
        
        # åˆ›å»ºç¤ºä¾‹è¾“å…¥
        dummy_input = torch.randn(1, input_size)
        
        print(f"ğŸ”„ è½¬æ¢ä¸ºONNX...")
        print(f"ğŸ“Š è¾“å…¥å°ºå¯¸: {dummy_input.shape}")
        
        # å¯¼å‡ºONNX
        torch.onnx.export(
            model,
            (dummy_input,),
            output_file,
            export_params=True,
            opset_version=11,
            do_constant_folding=True,
            input_names=['input'],
            output_names=['output'],
            dynamic_axes={
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            }
        )
        
        print(f"âœ… ONNXæ–‡ä»¶å·²ä¿å­˜: {output_file}")
        return True
        
    except Exception as e:
        print(f"âŒ ONNXè½¬æ¢å¤±è´¥: {e}")
        return False

def main():
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python convert_simple.py <model.pt>")
        print("ç¤ºä¾‹: python convert_simple.py model_walk.pt")
        return
    
    pt_file = sys.argv[1]
    
    if not os.path.exists(pt_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {pt_file}")
        return
    
    # 1. æ£€æŸ¥æ–‡ä»¶
    checkpoint = inspect_checkpoint(pt_file)
    if checkpoint is None:
        return
    
    # 2. æå–æ¨¡å‹ä¿¡æ¯
    model_info = extract_model_info(checkpoint)
    if model_info is None:
        return
    
    # 3. åˆ›å»ºæ¨¡å‹
    print("\nğŸ”§ é‡å»ºæ¨¡å‹...")
    model = create_simple_model(model_info)
    
    # 4. è½¬æ¢ä¸ºONNX
    output_file = pt_file.replace('.pt', '.onnx')
    print(f"\nğŸ¯ è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    success = convert_to_onnx(model, model_info['input_size'], output_file)
    
    if success:
        print("ğŸ‰ è½¬æ¢å®Œæˆ!")
        print(f"ğŸ“ ONNXæ–‡ä»¶: {output_file}")
    else:
        print("ğŸ’¥ è½¬æ¢å¤±è´¥!")

if __name__ == "__main__":
    main() 