# PT到ONNX模型转换指南

我为您创建了两个转换脚本来将Isaac Lab训练的.pt文件转换为ONNX格式：

## 🎯 推荐使用方法

### 方法一：简单转换脚本 (推荐)

```bash
python convert_simple.py your_model.pt
```

**特点：**
- ✅ 简单直接，适用于大多数情况
- ✅ 自动分析模型结构
- ✅ 不需要Isaac Lab环境
- ✅ 自动处理权重加载

**使用示例：**
```bash
# 转换模型文件
python convert_simple.py model_walk.pt

# 输出文件会自动命名为 model_walk.onnx
```

### 方法二：完整转换脚本

```bash
python convert_pt_to_onnx.py your_model.pt ./output_dir/ --verbose
```

**特点：**
- 🔧 使用Isaac Lab的官方导出器
- 📋 支持更多参数选项
- ⚠️ 需要Isaac Lab环境

## 📋 转换前检查

转换前，脚本会自动检查您的.pt文件结构：

```
🔍 检查文件: model_walk.pt
✅ 文件加载成功

📋 Checkpoint结构:
  model: dict (包含 123 个键)
    - actor.0.weight
    - actor.0.bias
    - actor.2.weight
    - actor.2.bias
    - actor.4.weight
    ... 还有 118 个键
  optimizer: dict (包含 6 个键)
  epoch: <class 'int'>
  step: <class 'int'>
```

## 🔧 转换过程

脚本会自动：
1. 📂 加载.pt文件
2. 🔍 分析网络结构
3. 🏗️ 重建PyTorch模型
4. ⚙️ 加载训练好的权重
5. 🔄 导出为ONNX格式

典型输出：
```
✅ 找到 3 个actor层
  层 actor.0.weight: 48 -> 512
  层 actor.2.weight: 512 -> 512  
  层 actor.4.weight: 512 -> 12

🔧 重建模型...
✅ 加载权重: actor.0.weight
✅ 加载偏置: actor.0.bias
✅ 加载权重: actor.2.weight
✅ 加载偏置: actor.2.bias
✅ 加载权重: actor.4.weight
✅ 加载偏置: actor.4.bias

🔄 转换为ONNX...
📊 输入尺寸: torch.Size([1, 48])
✅ ONNX文件已保存: model_walk.onnx
🎉 转换完成!
```

## 📁 文件结构

转换完成后，您会得到：
```
├── model_walk.pt        # 原始PyTorch模型
└── model_walk.onnx      # 转换后的ONNX模型
```

## 🛠️ 故障排除

### 1. 如果找不到actor权重
```
❌ 未找到actor权重
```
**解决方法：** 检查您的.pt文件是否包含完整的模型权重，或者模型结构与预期不同。

### 2. 如果网络结构无法识别
```
❌ 无法确定网络结构
```
**解决方法：** 可能需要根据您的具体模型结构调整脚本中的权重查找逻辑。

### 3. 如果ONNX转换失败
```
❌ ONNX转换失败: ...
```
**解决方法：** 检查PyTorch和ONNX版本兼容性，确保模型结构支持ONNX导出。

## 🔍 验证转换结果

转换完成后，您可以用以下方式验证ONNX模型：

```python
import onnx
import onnxruntime as ort

# 加载ONNX模型
model = onnx.load("model_walk.onnx")
print("ONNX模型信息:")
print(f"输入: {model.graph.input[0].name}")
print(f"输出: {model.graph.output[0].name}")

# 创建推理会话
session = ort.InferenceSession("model_walk.onnx")
print("✅ ONNX模型可以正常加载")
```

## 📞 技术支持

如果转换遇到问题，请提供：
1. 错误信息截图
2. .pt文件的checkpoint结构信息
3. 您使用的Isaac Lab版本和训练配置

这样我可以帮您调整转换脚本适配您的具体模型结构。 